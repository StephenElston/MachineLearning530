{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporation of Data\n",
    "## Data Science 350\n",
    "\n",
    "This notebook contains an introduction to the methods data scientists used to prepare and explore a data set. Data scientists spend a lot of time manipulating data to clean and prepare it (**data munging**) and to understand the relationships within the variables in the data (**data exporation**). Visualization is a key skill for any data scientist performing these tasks. \n",
    "\n",
    "Before performing any type of inference or machine learning on a data set, you should develop an underestanding of the relationships in the data set. Skipping this step can lead wasted time from unexpected problems when building models, or in constructing models with poor performance. When starting any data scince project, it is a good idea to plan on spending considerable time exploring the data. These exploration steps are often perfomed in conjunction with data cleaning and preparing, as visualiation often highlights problems with data. \n",
    "\n",
    "These lessons are divided into several parts. In each part you will learn how to use the visualization tools available in Python.\n",
    "\n",
    "- **Summarizing and manipulating data**:\n",
    "  * How large is it?\n",
    "  * What columns are of interest?\n",
    "  * Missing data?\n",
    "  * What are the characteristics of the data derrived from summary statistics and counts?\n",
    "- **Overview of Matplotlib, Pandas plotting and Seaborn** which are commonly used Python plotting packages. \n",
    "- **Overview of univariate plot types** is a reveiw of creating these basic plots using three Python packages. These plot types allow you to study the distributional properties of the variables in your data set. \n",
    "- **Using Matplotlib methods** to add attributes to plots, such as titles and axis labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Important!**  \n",
    "\n",
    "This notebook was constructed using the Anconda 3.5 Python distribution. If you are not running version Anaconda 3.5 or higher, we suggest you update your Anaconda distribution now.  You can download the Python 3 Anaconda distribution for your operating system from the [Continum Analytics web site](https://www.continuum.io/downloads\n",
    "\n",
    "To run this notebook you need the Seaborn graphics packages. If you have not done so, you will need to install Seaborn as it is not in the Anaconda distribution as of now. From a command prompt on your computer type the following command. If no errors occur, you will have installed Seaborn.\n",
    "\n",
    "``pip install seaborn``\n",
    "\n",
    "or\n",
    "\n",
    "``conda install seaborn``\n",
    "\n",
    "You can find more about installing ```seaborn``` can be seen on the [Installing and getting started](http://seaborn.pydata.org/installing.html) page.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data set\n",
    "\n",
    "This data set is from the [Univeristy of California Irving Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Automobile)  The data was compiled by Jeffrey C. Schlimmer from the following sources:\n",
    "\n",
    "- 1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook. \n",
    "- Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038 \n",
    "- Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and examine the data set\n",
    "\n",
    "Let's get started. The function shown in the cell below loads the data from the .csv file. Some minimal clean up is performed on the data. Rows with missing values are dropped and some columns are converted from strings containing numbers to numeric data. The result is a Pandas data frame.\n",
    "\n",
    "Execute the code in this cell to load the data into your notebook. **Make sure you have the .csv file in your working directory!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_auto_data(fileName = \"Automobile price data _Raw_.csv\"):\n",
    "    'Function to load the auto price data set from a .csv file' \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    ## Read the .csv file with the pandas read_csv method\n",
    "    auto_price = pd.read_csv(fileName)\n",
    "    \n",
    "    ## Remove rows with missing values, accounting for mising values coded as '?'\n",
    "    cols = ['price', 'bore', 'stroke', \n",
    "          'horsepower', 'peak-rpm']\n",
    "    for column in cols:\n",
    "        auto_price.loc[auto_price[column] == '?', column] = np.nan\n",
    "    auto_price.dropna(axis = 0, inplace = True)\n",
    "\n",
    "    ## Convert some columns to numeric values\n",
    "    for column in cols:\n",
    "        auto_price[column] = pd.to_numeric(auto_price[column])\n",
    "        \n",
    "    return auto_price\n",
    "auto_price = read_auto_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are some missing values in the numeric columns by the following steps:\n",
    "1. A list of the columns with the missing values is created.\n",
    "2. These data are coded by the `\"?\"` string. Each case where this strinng  occurs is replaced by a numpy `nan`, a missing value. \n",
    "3. Then rows containing `nan` removed from the data frame. \n",
    "4. The type of these columns is then coerced to numeric. \n",
    "\n",
    "Next, have a first look at the dimensions and data types of the columnof the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(auto_price.shape)\n",
    "print(auto_price.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key things to notice here are:\n",
    "\n",
    "- There are 195 rows or cases in the data set.\n",
    "- The data set has 26 variables or columns.\n",
    "- Columns have a type of either `object` (character), `float64` (floating point number), or `int64` (integer). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "\n",
    "You can also learn a lot about a data set by looking at statistical summaries. The Pandas `describe` method does just this. Execute the code in the cell below and note the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, that summary statistics are only provided for numeric columns. For these column this summary provides some useful information:\n",
    "\n",
    "- The minimum and maximum values of each variable are displayed.\n",
    "- The quantiles are shown; 25%, 50% (median), 75%. Note that, for several of theses variables, the upper interquartile ranges (IQR) are different from the lower IQR, indicating the distributions are skewed. \n",
    "- The mean is displayed. Compare the mean and the median, noting that the are often quite different. Again this is a sign of a skewed distribution. \n",
    "- The standard deviation gives a measure of the dispersion of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data frames\n",
    "\n",
    "Next, let's look at the first and last few lines of the data frame using the `head` and `tail` methods. Execute the code in the cells below to examine the first 10 rows and last 5 rows (the default) of the data frame, using the `head` and `tail` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_price.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_price.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these result to get feel for the data contained in the columns of this data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency tables\n",
    "\n",
    "The summary techniques we have used so far are suitable only for numeric variables. Categorical variables have values which are typically unordered. Therefore, we need a method to summrize categorical based on counts.  \n",
    "\n",
    "The Pandas `group_by` method lets you subset a data frame by a list of columns. The data are grouped into a heirarchy by the order of the columns spcified. Notice that the `groupby` operation only makes sense for categorical variables. \n",
    "\n",
    "The Pandas `agg` or agregation method can be used to compute summary statistics. In this case, we will use the `count` operator. The frequency table shows the count of each category of the variable. \n",
    "\n",
    "To ensure the results display in an easy to understand manner, we will create a new column in the dataframe called `counts`. This column contains integer `1` values. The number of elements in each group can be counted, or simply summed.  \n",
    "\n",
    "Execute the following code to show the number of cars in the data set by unique manufacturer.\n",
    "\n",
    "***\n",
    "**Code note:** \n",
    "\n",
    "Operations on Pandas data frames can be applied using methods. The methods can be chained using the `.` operator.  \n",
    "\n",
    "The second line of code below performs several operations:\n",
    "1. The required columns are subsetted using the `[]` operator on the list of column names.\n",
    "2. The `groupby` method is applied to the subsetted data frame. The argument to `groupby` is the list of column names.\n",
    "3. The `agg` method is applied to the grouped data. The operations to apply to the groups are the arguments to this method. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto_price['counts'] = 1\n",
    "auto_price[['counts', 'make']].groupby(['make']).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine this result. The name of the `make` is in one column and the count is in the other. Notice that some manufactures like alfa-romero and chevrolet have only three cars types in the sample. Toyota has the most cars in this sample. \n",
    "\n",
    "Or, you can look at the frquency of a combination of two categorical variables. The groups are organized by the order of theh columns specified. Execute the code in the cell below and examine the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_price[['counts', 'fuel-type', 'make']].groupby(['make', 'fuel-type']).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine this result. The data are grouped frist by `make` and then by engine `fuel-type`. This table gives us a feel for which manufactures only make gas cars and which ones make both gas and diesel cars, and how many of each. Notice that groups with counts of zereo do not display in the table. \n",
    "\n",
    "Frequency tables with multiple levels of grouping can be easily displayed\n",
    ". Execute the code in the cell below and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_price[['counts', 'fuel-type', 'aspiration', 'make']].groupby(['make', 'fuel-type', 'aspiration']).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with three levels the table takes a bit more effort to examine. As the number of grouping levels increases, frequency tables become progressively more difficult to understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn:** In the cell below, create and execute the code to create a frequency table of autos by body style and number of doors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine your results and answer these questions. \n",
    "1. Which body style and door configuration is the most frequent? \n",
    "2. Ignoring missing values, which body style and door configuration is the least frequent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration and Visualization of Data\n",
    "\n",
    "### Why visualization?\n",
    "\n",
    "Visualization is an essential method in any data scientistâ€™s toolbox. Visualization is a key first step in the exploration of most data sets. As a general rule, you should never start creating models until you have examined the data and understand the relationships. Otherwise, you risk wasting your time creating models blindly. Visualization is also a powerful tool for presentation of results and for determining sources of problems with analytics. \n",
    "\n",
    "The concepts of exploring a data set visually were pioneered by John Tukey in the 1960s and 1970s. Tukey consolidated his many ideas on data exploration into a book in the late 1970s, ***John Tukey, Exploratory Data Analysis, 1977, Addison-Westley***.\n",
    "\n",
    "![](img/Tukey.jpg)\n",
    "\n",
    "Bill Cleveland documented his seminal work in visualization of complex data sets in his book, ***William S. Cleveland, Visualizing Data, 1993, Hobart Press***.\n",
    "\n",
    "![](img/Cleveland.jpg)\n",
    "\n",
    "The key concept of exploratory data analysis (EDA) or visual exploration of data is to understand the relationships in the data set. Specifically using visualization when you approach a new data set you can:\n",
    "\n",
    "- Explore complex data sets, using visualization to develop understanding of the inherent relationships.\n",
    "- Use different chart types to create multiple views of data to highlight different aspects of the inherent relationships.\n",
    "- Use plot aesthetics to project multiple dimensions. \n",
    "- Apply conditioning or faceting methods to project multiple dimensions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The confusing world of Python graphics libraries. \n",
    "\n",
    "There are a number of powerful charting packages available for the Python language. This situation can lead to confusion as to which package to use for which situation. Below is an outline to help you understand the organization of Python grapics choices:\n",
    "https://bokeh.pydata.org/en/latest/\n",
    "- **Matplotlib:** [Matplotlib](https://matplotlib.org/users/index.html) is a low-level scientific and technical charting package. A number of other Python charting libraries are built on top of Matplotlib. As a result, a bit of knowledge of Matplotlib will help you set the attributes of plots created with several other packages. An extensive [tutorial](https://matplotlib.org/tutorials/index.html) is available for Matplotlib.\n",
    "- **Pandas plotting:** The [visualization methods for Pandas](https://pandas.pydata.org/pandas-docs/stable/visualization.html) provides a simple interface for common plot types for data in data frames. As with many other Python plotting libraries Pandas visualization is built on top of Matplotlib. You can use common Matplotlib methods with Pandas visualization. \n",
    "- **Seaborn:** The [Seaborn](https://seaborn.pydata.org/) package privides high-level api for statistical graphics. As with many other Python plotting libraries Seaborn is built on top of Matplotlib. You can use common Matplotlib methods with Seaborn.  A [tutorial](https://seaborn.pydata.org/tutorial.html) with useful examples is available for Seaborn.   \n",
    "- **Other packages:** There are a number of other sophisticated and useful Python graphics packages. Unfortunately, we do not have time in this course to cover these packages. The Python [ggplot](http://ggplot.yhathq.com/) package provideds a high-level graphics interface based on the grammar of graphics used in the R ggplot2 package.  There are two powerful Python interactive graphics packages which are widely used, [plotly](https://plot.ly/python/) and [Bokeh](https://bokeh.pydata.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic chart types\n",
    "\n",
    "Now that you have loaded and had a first look at the data, its time to get to work making some charts.   \n",
    "\n",
    "There are enumerable chart types that are used for data exploration. When exploring a data set you need to examine multiple views. This process will require using multiple chart types. \n",
    "\n",
    "All computer data graphics are projected onto a 2-dimensional surface.  This is a fundamentail restriction on data visualization we must learn to work with. Very broadly, plots are one-dimensional (univariate) or 2-dimensional (bi-variate). We will study plots of both types in this lesson.   \n",
    "\n",
    "In this lesson you will work with a number of common chart types. The list below indicates the plots we will explore and an indication about the dimensionality of the plot:\n",
    "\n",
    "- **Bar plots** - 1d\n",
    "- **Histograms** - 1d\n",
    "- **Box plots** - 1d +\n",
    "- **Kernel Density Estimation Plots** - 1d +\n",
    "- **Violin plots** -1d +\n",
    "- **Scatter plot** - 2d\n",
    "- **2d Kernel Density Plots** -2d\n",
    "- **Hexbin plots** - 2d\n",
    "- **Line plots** - 2d\n",
    "\n",
    "The following exercises give you some practice using these chart types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots\n",
    "\n",
    "To start our exploration of of these data we will work with bar plots. Bar plots are used to display the counts or frequency of unique values of a categorical variable. The height of the bar represents the count for each unique category of the variable. \n",
    "\n",
    "The code below uses chain of Pandas methods to display a barplot of the counts by body style. This chain performs the following operations:\n",
    "1. The required columns are selected using the `loc` method. The `loc` method selects rows, or columns by name, not index number (use `iloc`). In this case we are selecting columns by a list of two names.\n",
    "2. The `groupby` method groups the data in the order of the columns in the list.\n",
    "3. The `agg` method performs aggregation on the groups. In this case we are only applying a count operation.\n",
    "4. The Pandas `plot.bar` method creates the bar plot. Notice how the `bar` method of `plot` specifies the plot type. This syntax can be used for all Pandas plot types.\n",
    "\n",
    "The Jupyter 'magic' command `matplotlib inline` tells the interpreter to display matplotlib graphics inline in the notebook.\n",
    "\n",
    "Execute this code to create the bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "auto_price.loc[:, ['body-style', 'counts']].groupby(['body-style']).agg('count').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From this display you can see that sedan is the most frequent body type is sedan and the least frequent is convertible. \n",
    "\n",
    "It would be easier to understand this plot if the frequencies of the categories were ordered. This would be particularly true if there were a large number of categories or categories with similar counts. \n",
    "\n",
    "The code in the cell below adds a `sort_values` operation to the chain of methods. The counts will be ordered from lowest to highest. \n",
    "\n",
    "Execute the code in the cell below to create an ordered bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auto_price.loc[:, ['body-style', 'counts']].groupby(['body-style']).agg('count').sort_values('counts').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn!** In the cell below, create and execute the code to create a sorted bar chart of the number of doors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine your plot and answer the following questions:\n",
    "1. Is there evidence of missing values? \n",
    "2. Which number of doors is the most common? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "Histograms are related to bar plots. Histograms are used for numeric variables. Whereas, a bar plot shows the counts of unique categories, a histogram shows the number of data with values in each bin. The bins divide the values of the variable into equal segments. The vertical axis of the histogram shows the count of data values within each bin.  \n",
    "\n",
    "The code in the cell below uses the Pandas `plot` method once again, but with the `hist` method this time. The optional `bins = 30` argument customizes the appearance of the histogram. Notice that the use of the Pandas plotting method is a variation on the bar plots you just created. \n",
    "\n",
    "Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_price.loc[:,'price'].plot.hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that the price of automobiles are skewed toward the lower end, with only a few high priced autos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "\n",
    "Box plots, also known as box and wisker plots, were introduced by John Tukey in 1970. Box plots are another way to visualize the distribution of data values. In this respect, box plots are comparable to histograms, but are quite different in presentation. \n",
    "\n",
    "A diagram showing the interpretation of a box plot is shown in the figure below.\n",
    "\n",
    "![Interpretation of a box plot](img/BoxPlot.png)\n",
    "\n",
    "At first glance the interpretation of a box plot is a bit intimidating. The box plot is read in the following maner:\n",
    "\n",
    "1. The bold line in the box shows the median of the distribution. \n",
    "2. The upper and lower middle quartiles of the distribution define the upper and lower limits of the box.\n",
    "3. The length of the the wiskers is the lesser of +/-2.5 times the inter-quartile range (about 2.7 times the standard deviation) or the most extreme values of the data. \n",
    "4. Outliers are shown by symbols, such as `+` or `*`, beyond the wiskers.\n",
    "\n",
    "Box plots are best used to compare distributions of a variable grouped by another variable. In this case, several box plots can be stacked along an axis. The data are divided using a 'group by' operation, and the box plots for each group are stacked next to each other. In this way, the box plot allows you to display two dimensions of your data set. \n",
    "\n",
    "The code in the cell below uses the matplotlib boxplot method. The only argument is the single data vector. Execute the code in the cell below to create a basic box plot of the price of the automobiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(auto_price.loc[:,'price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the above plot to the histogram of price. You can see from both plots that the distribution of price is quite asymmetric. Further, there are a significant number of high-priced cars that appear as outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot, is quite basic. Most importantly, this plot lacks the annotation required for someone to quickly understand it. At the minimum a title and an axis lable are required. Fortunately, adding these attributes to the plot is realatively easy, since matplotlib provides methods to do so. \n",
    "\n",
    "There is another issue with this plot. Notice that the limits of the y axis is $\\{ 5000, 50000 \\}$. The fact that this limit does not include `0` can distort the observer's view of the data. This is particularly the case when making comparisons between variables, of subsets of variables. In general, the vertical axis limit of  plots should include `0`.\n",
    "\n",
    "It will also be useful to have control of other plot attributes like overall size. \n",
    "\n",
    "The basic recipe is as follows:\n",
    "\n",
    "1. A matplotlib figure object is created. The `figsize` arguments sets the size of the plot area.\n",
    "2. A axis object is created for the figure.\n",
    "3. The box plot is added to the axis object.\n",
    "4. Title text is added to the axis object.\n",
    "5. A y axis label is added to the axis object. \n",
    "6. The limits for the y axis are set to include 0. \n",
    "\n",
    "***\n",
    "**Note:** There are many other attributes which can be set by with matplotlib. \n",
    "***\n",
    "\n",
    "Execute the code to create the plot and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6)) # define plot area\n",
    "ax = fig.gca() # define axis \n",
    "plt.boxplot(auto_price.loc[:,'price'])\n",
    "ax.set_title('Box plot of price') # Give the plot a main title\n",
    "ax.set_ylabel('Auto Price')# Set  text for y axis\n",
    "ax.set_ylim(0.0, 50000.0) # Set the limits of the y axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots are most useful when the data are subdivided or grouped using another variable. The `by` argument allows you to group the data in a set of box plots by one or more categorical variables. \n",
    "\n",
    "For the code in the cell below we will use the Pandas `boxplot` method directly. Notice the `ax = ax` argument which places on the plot on the axis which has been defined. The matplotlib methods can then be used on this axis to add attributes to the plot. \n",
    "\n",
    "Execute the code below to display the box plots of price grouped by the `fuel.type` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6)) # define plot area\n",
    "ax = fig.gca() # define axis \n",
    "auto_price.loc[:,['price', 'fuel-type']].boxplot(by = 'fuel-type', ax = ax)\n",
    "ax.set_title('Box plot of price') # Give the plot a main title\n",
    "ax.set_ylabel('Auto Price')# Set text for y axis\n",
    "ax.set_ylim(0.0, 50000.0) # Set the limits of the y axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Examine these box plots and note the following:\n",
    "\n",
    "- The median price of gas autos is less than the the median price for diesel autos.\n",
    "- There is considerable overlap between the interquartile ranges of the price distributions of gas and diesel autos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn!** In the cell below create and execute the code to display a box plot of auto price grouped by both `fuel-type` and `aspiration`. You will need to include the following in your code:\n",
    "\n",
    "1. Define figure and axis object.\n",
    "2. Add a box plot to the axis using the Pandas boxplot method. The `by` argument will be a list of column names.\n",
    "3. Set some attributes of your plot, including a title, an x-axis label and a y-axis label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine this plot and answer the following questions. \n",
    "1. Are turbo diesel cars generally more expensive that standard gas and diesel cars, and why? \n",
    "2. Which type of car shows the greatest price range and the most outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel density estimation plots\n",
    "\n",
    "You have used two methods for visualizing distributions. Now, you will look at another method, kernel density estimation. Kernel density estimation uses a moving window denisty estimation kernel to average the density of the distribution. The result is a smoothed estimate of the probability density of the variable.\n",
    "\n",
    "In the cell below we will use the Python `seaborn` package to plot the kernel density estimation plot. The code uses the following recipe to create and display the plot:\n",
    "1. Define a figure and an axis on that figure.\n",
    "2. A seaborn grid is defined, with the style as the argument.\n",
    "3. The seaborn `kdeplot` method is used on the vector of values to be plotted.\n",
    "4. Add plot attributes using matplotlib methods.\n",
    "\n",
    "Notice that, once again, we add attributes to the plot using matplotlib methods. \n",
    "\n",
    "***\n",
    "**Note:** Depending on which version of the numpy and statsmodels packages you are running, you may get a deprication warning.\n",
    "***\n",
    "\n",
    "Execute the code in the cell below to compute and plot a kernel density estimate of auto price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(6,6)) # define plot area\n",
    "ax = fig.gca() # define axis \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.kdeplot(auto_price.loc[:, 'price'], ax = ax)\n",
    "ax.set_title('KDE plot of auto price') # Give the plot a main title\n",
    "ax.set_xlabel('Auto price') # Set text for the x axis\n",
    "ax.set_ylabel('Density')# Set text for y axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine this plot. Notice that the distribution is heavily skewwed to the left or low side. This finding is consistent with the other displays you have created with histograms and box plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plots\n",
    "\n",
    "Violin plots are a useful, and relatively new, plot type. The violin plot combines some attributes of a kernal density plot and the box plot. The violin plot shows a pair of symetric kernel desity plot. The violin plot has the advantage, and perhaps disadvantage, of showing more . Like a box plot, the violin plot can be conditioned on a categorical (factor) variable, so distributions of a grouped variable can be compared. \n",
    "\n",
    "The code in the cell below creates a violin plot of auto price, grouped by fuel type. Notice that `price` is the y (or vertical) axis argument and the grouping variable, `fuel-type`, is the x (or horizontal) axis argument. \n",
    "\n",
    "As before, we use the matplotlib methods to add attributes to this plot.\n",
    "\n",
    "Execute this code to create the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6)) # define plot area\n",
    "ax = fig.gca() # define axis \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.violinplot(x = 'fuel-type', y = 'price', data = auto_price, ax = ax)\n",
    "ax.set_title('KDE plot of auto price by fuel type') # Give the plot a main title\n",
    "ax.set_xlabel('Auto price') # Set text for the x axis\n",
    "ax.set_ylabel('Fuel type')# Set text for y axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine this plot and  notice the following:\n",
    "1. The price of gas and diesel cars overlap quite a lot. \n",
    "2. The outliers of price for gas cars are clearly visible.\n",
    "3. The median (white dot), inner quartiles (black box), and wiskers at +/-2.5 of the IQR are all visible inside the violin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn!** In the cell below create and execute the code to display a violin of auto price grouped by `fuel-type` and `aspiration`. Seaborn allows you to group by the `x` varible and by `hue` (color). In this case, use the arguments `x = 'fuel-type'` and `hue = 'aspiration'`. You should also try the alternative display option, `split = True`, which shows split violin plots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine your plot and answer the following questions. \n",
    "1. Which category of autos has the smallest range of prices? \n",
    "2. Are turbo diesel cars generally more expensive and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You have covered a lot of ground in this tutorial. You have explored many of the relationships in the auto price data set by creating multiple views to visualize these data. \n",
    "\n",
    "Specifically, in this tutoral you have:\n",
    "\n",
    "- Applied multiple summary statistical and multiple plot views to develop an in-depth understanding of a data set.  \n",
    "- Used Pandas methods to prepare and explore data. The Pandas package provideds powerful methods for exploring a new data set.\n",
    "- Examined the uses of and methods for creation of several univariate plot types using three different Python packages, matplotlib, Pandas, and seaborn. Univariate plots allow you to examine the distributional properties of the variables in your data set. The variable values can be grouped by one or more categorical variables for comparison.\n",
    "- Used matplotlib methods to add attributes to matplotlib, Pandas and seaborn plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
